{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrrajatgarg/StackGAN/blob/master/stackgan_stage_I_imp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fBRj1Lxsle4H"
      },
      "source": [
        "# Stage I GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "psC9UHjzliA1"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "ml58N7F-jnLh",
        "outputId": "e2dd3ad8-ccd0-4c1d-bee9-bf5ab682881a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "import PIL\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from keras import Input, Model\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n",
        "    concatenate, Flatten, Lambda, Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XZybHodapH3H"
      },
      "source": [
        "# Loading of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "eMvLOjXalnKd"
      },
      "outputs": [],
      "source": [
        "def load_class_ids(class_info_file_path):\n",
        "    \"\"\"\n",
        "    Load class ids from class_info.pickle file\n",
        "    \"\"\"\n",
        "    with open(class_info_file_path, 'rb') as f:\n",
        "        class_ids = pickle.load(f, encoding='latin1')\n",
        "        return class_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ifdCVSGco5pD"
      },
      "outputs": [],
      "source": [
        "def load_embeddings(embeddings_file_path):\n",
        "    \"\"\"\n",
        "    Load embeddings\n",
        "    \"\"\"\n",
        "    with open(embeddings_file_path, 'rb') as f:\n",
        "        embeddings = pickle.load(f, encoding='latin1')\n",
        "        embeddings = np.array(embeddings)\n",
        "        print('embeddings: ', embeddings.shape)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fkwKbQgvo7pG"
      },
      "outputs": [],
      "source": [
        "def load_filenames(filenames_file_path):\n",
        "    \"\"\"\n",
        "    Load filenames.pickle file and return a list of all file names\n",
        "    \"\"\"\n",
        "    with open(filenames_file_path, 'rb') as f:\n",
        "        filenames = pickle.load(f, encoding='latin1')\n",
        "    return filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YxlUAsjuo-i5"
      },
      "outputs": [],
      "source": [
        "def load_bounding_boxes(dataset_dir):\n",
        "    \"\"\"\n",
        "    Load bounding boxes and return a dictionary of file names and corresponding bounding boxes\n",
        "    \"\"\"\n",
        "    # Paths\n",
        "    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n",
        "    file_paths_path = os.path.join(dataset_dir, 'images.txt')\n",
        "\n",
        "    # Read bounding_boxes.txt and images.txt file\n",
        "    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n",
        "                                    delim_whitespace=True, header=None).astype(int)\n",
        "    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n",
        "\n",
        "    # Create a list of file names\n",
        "    file_names = df_file_names[1].tolist()\n",
        "\n",
        "    # Create a dictionary of file_names and bounding boxes\n",
        "    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n",
        "\n",
        "    # Assign a bounding box to the corresponding image\n",
        "    for i in range(0, len(file_names)):\n",
        "        # Get the bounding box\n",
        "        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n",
        "        key = file_names[i][:-4]\n",
        "        filename_boundingbox_dict[key] = bounding_box\n",
        "\n",
        "    return filename_boundingbox_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NQf-MsWtpAyk"
      },
      "outputs": [],
      "source": [
        "def get_img(img_path, bbox, image_size):\n",
        "    \"\"\"\n",
        "    Load and resize image\n",
        "    \"\"\"\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    width, height = img.size\n",
        "    if bbox is not None:\n",
        "        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
        "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
        "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
        "        y1 = np.maximum(0, center_y - R)\n",
        "        y2 = np.minimum(height, center_y + R)\n",
        "        x1 = np.maximum(0, center_x - R)\n",
        "        x2 = np.minimum(width, center_x + R)\n",
        "        img = img.crop([x1, y1, x2, y2])\n",
        "    img = img.resize(image_size, PIL.Image.BILINEAR)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gk-4oF83Su2v"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BEtbSBB8pCfo"
      },
      "outputs": [],
      "source": [
        "def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n",
        "    \"\"\"\n",
        "    Load dataset\n",
        "    \"\"\"\n",
        "    filenames = load_filenames(filenames_file_path)\n",
        "    class_ids = load_class_ids(class_info_file_path)\n",
        "    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n",
        "    all_embeddings = load_embeddings(embeddings_file_path)\n",
        "\n",
        "    X, y, embeddings = [], [], []\n",
        "\n",
        "    print(\"Embeddings shape:\", all_embeddings.shape)\n",
        "\n",
        "    for index, filename in enumerate(filenames):\n",
        "        bounding_box = bounding_boxes[filename]\n",
        "\n",
        "        try:\n",
        "            # Load images\n",
        "            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n",
        "            img = get_img(img_name, bounding_box, image_size)\n",
        "\n",
        "            all_embeddings1 = all_embeddings[index, :, :]\n",
        "\n",
        "            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n",
        "            embedding = all_embeddings1[embedding_ix, :]\n",
        "\n",
        "            X.append(np.array(img))\n",
        "            y.append(class_ids[index])\n",
        "            embeddings.append(embedding)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    embeddings = np.array(embeddings)\n",
        "    return X, y, embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ODvYdkGtpGKJ"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "__1ejH3mpFon"
      },
      "outputs": [],
      "source": [
        "def generate_c(x):\n",
        "    mean = x[:, :128]\n",
        "    log_sigma = x[:, 128:]\n",
        "    stddev = K.exp(log_sigma)\n",
        "    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\n",
        "    c = stddev * epsilon + mean\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LYGM28snpPMb"
      },
      "outputs": [],
      "source": [
        "def build_ca_model():\n",
        "    \"\"\"\n",
        "    Get conditioning augmentation model.\n",
        "    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(1024,))\n",
        "    x = Dense(256)(input_layer)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    model = Model(inputs=[input_layer], outputs=[x])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jY_cMcEbpRSW"
      },
      "outputs": [],
      "source": [
        "def build_embedding_compressor_model():\n",
        "    \"\"\"\n",
        "    Build embedding compressor model\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(1024,))\n",
        "    x = Dense(128)(input_layer)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[x])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "N5BK6rWkpSyQ"
      },
      "outputs": [],
      "source": [
        "def build_stage1_generator():\n",
        "    \"\"\"\n",
        "    Builds a generator model used in Stage-I\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(1024,))\n",
        "    x = Dense(256)(input_layer)\n",
        "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    c = Lambda(generate_c)(mean_logsigma)\n",
        "\n",
        "    input_layer2 = Input(shape=(100,))\n",
        "\n",
        "    gen_input = Concatenate(axis=1)([c, input_layer2])\n",
        "\n",
        "    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    x = Activation(activation='tanh')(x)\n",
        "\n",
        "    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\n",
        "    return stage1_gen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xJLclqSTpVGj"
      },
      "outputs": [],
      "source": [
        "def build_stage1_discriminator():\n",
        "    \"\"\"\n",
        "    Create a model which takes two inputs\n",
        "    1. One from above network\n",
        "    2. One from the embedding layer\n",
        "    3. Concatenate along the axis dimension and feed it to the last module which produces final logits\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(64, 64, 3))\n",
        "\n",
        "    x = Conv2D(64, (4, 4),\n",
        "               padding='same', strides=2,\n",
        "               input_shape=(64, 64, 3), use_bias=False)(input_layer)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    input_layer2 = Input(shape=(4, 4, 128))\n",
        "\n",
        "    merged_input = concatenate([x, input_layer2])\n",
        "\n",
        "    x2 = Conv2D(64 * 8, kernel_size=1,\n",
        "                padding=\"same\", strides=1)(merged_input)\n",
        "    x2 = BatchNormalization()(x2)\n",
        "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
        "    x2 = Flatten()(x2)\n",
        "    x2 = Dense(1)(x2)\n",
        "    x2 = Activation('sigmoid')(x2)\n",
        "\n",
        "    stage1_dis = Model(inputs=[input_layer, input_layer2], outputs=[x2])\n",
        "    return stage1_dis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NREfScoDpXKb"
      },
      "outputs": [],
      "source": [
        "def build_adversarial_model(gen_model, dis_model):\n",
        "    input_layer = Input(shape=(1024,))\n",
        "    input_layer2 = Input(shape=(100,))\n",
        "    input_layer3 = Input(shape=(4, 4, 128))\n",
        "\n",
        "    x, mean_logsigma = gen_model([input_layer, input_layer2])\n",
        "\n",
        "    dis_model.trainable = False\n",
        "    valid = dis_model([x, input_layer3])\n",
        "\n",
        "    model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[valid, mean_logsigma])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eNBHRmpqpZgo"
      },
      "source": [
        "# Defining Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "awQ2XK6lpZDr"
      },
      "outputs": [],
      "source": [
        "def KL_loss(y_true, y_pred):\n",
        "    mean = y_pred[:, :128]\n",
        "    logsigma = y_pred[:, :128]\n",
        "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n",
        "    loss = K.mean(loss)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "S6wkVR9lpd5q"
      },
      "outputs": [],
      "source": [
        "\n",
        "def custom_generator_loss(y_true, y_pred):\n",
        "    # Calculate binary cross entropy loss\n",
        "    return K.binary_crossentropy(y_true, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1wGTNAxZpfoc"
      },
      "outputs": [],
      "source": [
        "def save_rgb_img(img, path):\n",
        "    \"\"\"\n",
        "    Save an rgb image\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Image\")\n",
        "\n",
        "    plt.savefig(path)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vfdGkJj0phPb"
      },
      "outputs": [],
      "source": [
        "def write_log(callback, name, loss, batch_no):\n",
        "    \"\"\"\n",
        "    Write training summary to TensorBoard\n",
        "    \"\"\"\n",
        "    summary = tf.Summary()\n",
        "    summary_value = summary.value.add()\n",
        "    summary_value.simple_value = loss\n",
        "    summary_value.tag = name\n",
        "    callback.writer.add_summary(summary, batch_no)\n",
        "    callback.writer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JWRKO6IfpkFt"
      },
      "source": [
        "# Main File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6Pjt8uWEpjsS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from keras.callbacks import TensorBoard\n",
        "import time\n",
        "from PIL import Image\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_filenames(file_path):\n",
        "    \"\"\"Loads filenames from a pickle file.\"\"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        filenames = pickle.load(f)\n",
        "    return filenames\n",
        "\n",
        "def load_class_ids(file_path):\n",
        "    \"\"\"Loads class IDs from a pickle file.\"\"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        class_ids = pickle.load(f)\n",
        "    return class_ids\n",
        "\n",
        "def load_bounding_boxes(cub_dataset_dir):\n",
        "    \"\"\"\n",
        "    Placeholder: In real code, you'd load bounding boxes from .txt or .pickle.\n",
        "    Returns a dict of {filename: (x, y, width, height)} or similar.\n",
        "    \"\"\"\n",
        "    # For simplicity, return an empty dict or random boxes\n",
        "    return {}\n",
        "\n",
        "def load_embeddings(embeddings_file_path):\n",
        "    \"\"\"Loads embeddings from a pickle file.\"\"\"\n",
        "    with open(embeddings_file_path, \"rb\") as f:\n",
        "        all_embeddings = pickle.load(f)\n",
        "    return all_embeddings\n",
        "\n",
        "def get_img(img_path, bounding_box, image_size):\n",
        "    \"\"\"\n",
        "    Loads and returns a resized image. \n",
        "    bounding_box is ignored here, but you could crop the image accordingly if needed.\n",
        "    \"\"\"\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    img = img.resize(image_size, Image.ANTIALIAS)\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------------------\n",
        "# 1) Conditioning Augmentation (CA) Model\n",
        "#    Takes an embedding and learns mu/logvar, then reparameterizes to produce c\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def build_ca_model(embedding_dim=1024, condition_dim=128):\n",
        "    \"\"\"\n",
        "    CA model that takes text embedding of size embedding_dim and\n",
        "    outputs a (condition_dim)-dim vector c after reparameterization.\n",
        "    \"\"\"\n",
        "    embedding_input = layers.Input(shape=(embedding_dim,))\n",
        "    x = layers.Dense(256, activation=\"relu\")(embedding_input)\n",
        "    mu = layers.Dense(condition_dim)(x)\n",
        "    logvar = layers.Dense(condition_dim)(x)\n",
        "\n",
        "    # We'll output mu and logvar; the reparameterization trick can be done outside\n",
        "    model = keras.Model(inputs=embedding_input, outputs=[mu, logvar])\n",
        "    return model\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# 2) KL Divergence Loss for the CA Model\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def KL_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    The second output of the adversarial model is (mu, logvar),\n",
        "    but we typically compute KL inside the CA pipeline. \n",
        "    Here is a placeholder that expects y_pred = [mu, logvar] concatenated \n",
        "    or another custom approach. For simplicity, let's do a naive version.\n",
        "    \"\"\"\n",
        "    # Suppose we packed mu and logvar along the last dimension\n",
        "    # i.e. y_pred.shape == (batch_size, condition_dim*2)\n",
        "    half = y_pred.shape[-1] // 2\n",
        "    mu = y_pred[:, :half]\n",
        "    logvar = y_pred[:, half:]\n",
        "    # KL\n",
        "    kld = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mu) - tf.exp(logvar), axis=1)\n",
        "    return tf.reduce_mean(kld)\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# 3) Embedding Compressor (optional)\n",
        "#    Sometimes used to reduce embedding dim (e.g., 1024 -> 128)\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def build_embedding_compressor_model(embedding_dim=1024, condition_dim=128):\n",
        "    \"\"\"\n",
        "    Simple FC to reduce large embedding_dim -> condition_dim\n",
        "    \"\"\"\n",
        "    embedding_input = layers.Input(shape=(embedding_dim,))\n",
        "    x = layers.Dense(condition_dim, activation=\"relu\")(embedding_input)\n",
        "    model = keras.Model(inputs=embedding_input, outputs=x)\n",
        "    return model\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# 4) Stage 1 Generator\n",
        "#    Takes random noise z + condition c, outputs a 64x64 image\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def build_stage1_generator(z_dim=100, condition_dim=128):\n",
        "    \"\"\"\n",
        "    Example DCGAN-like generator for 64x64 output.\n",
        "    Input: concatenated [z (100), c (128)]\n",
        "    Output: 64x64x3\n",
        "    \"\"\"\n",
        "    input_layer = layers.Input(shape=(z_dim + condition_dim,))\n",
        "\n",
        "    x = layers.Dense(4*4*256, use_bias=False)(input_layer)\n",
        "    x = layers.Reshape((4, 4, 256))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64, (4,4), strides=(2,2), padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(3, (4,4), strides=(2,2), padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.Activation(\"tanh\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=input_layer, outputs=x)\n",
        "    return model\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# 5) Stage 1 Discriminator\n",
        "#    Takes 64x64 image + condition embedding, outputs real/fake\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def build_stage1_discriminator(condition_dim=128):\n",
        "    \"\"\"\n",
        "    Discriminator that also takes text embedding. \n",
        "    For simplicity, we project the embedding to a spatial map and concatenate.\n",
        "    \"\"\"\n",
        "    # Image input\n",
        "    image_input = layers.Input(shape=(64, 64, 3))\n",
        "    # Condition input\n",
        "    cond_input = layers.Input(shape=(condition_dim,))\n",
        "\n",
        "    # Downsample image\n",
        "    x_img = layers.Conv2D(64, (4,4), strides=(2,2), padding=\"same\")(image_input)\n",
        "    x_img = layers.LeakyReLU(alpha=0.2)(x_img)\n",
        "\n",
        "    x_img = layers.Conv2D(128, (4,4), strides=(2,2), padding=\"same\")(x_img)\n",
        "    x_img = layers.BatchNormalization()(x_img)\n",
        "    x_img = layers.LeakyReLU(alpha=0.2)(x_img)\n",
        "\n",
        "    x_img = layers.Conv2D(256, (4,4), strides=(2,2), padding=\"same\")(x_img)\n",
        "    x_img = layers.BatchNormalization()(x_img)\n",
        "    x_img = layers.LeakyReLU(alpha=0.2)(x_img)\n",
        "\n",
        "    # Project condition to 4x4\n",
        "    cond = layers.Dense(4*4, activation=\"relu\")(cond_input)\n",
        "    cond = layers.Reshape((4, 4, 1))(cond)\n",
        "\n",
        "    # Concatenate condition map with image\n",
        "    x = layers.Concatenate(axis=-1)([x_img, cond])\n",
        "\n",
        "    x = layers.Conv2D(256, (3,3), strides=(1,1), padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Flatten & final output\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=[image_input, cond_input], outputs=x)\n",
        "    return model\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# 6) Adversarial Model\n",
        "#    Wires up Generator + Discriminator for generator training\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def build_adversarial_model(gen_model, dis_model, ca_model, z_dim=100, condition_dim=128):\n",
        "    \"\"\"\n",
        "    The 'adversarial model' is used to train the generator end-to-end:\n",
        "     - Input: [noise (z), text embedding]\n",
        "     - Output: [discriminator score, KL info (mu+logvar)]\n",
        "    \"\"\"\n",
        "    # Noise + text embedding as input\n",
        "    embedding_input = layers.Input(shape=(1024,))\n",
        "    z_input = layers.Input(shape=(z_dim,))\n",
        "\n",
        "    # CA model -> mu, logvar\n",
        "    mu, logvar = ca\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training data...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './data/coco/train\\\\class_info.pickle'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 2) Load Training Data\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m X_train, y_train, embeddings_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilenames_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilenames_file_path_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_info_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_info_file_path_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcub_dataset_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_file_path_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading test data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m X_test, y_test, embeddings_test \u001b[38;5;241m=\u001b[39m load_dataset(\n\u001b[0;32m     53\u001b[0m     filenames_file_path\u001b[38;5;241m=\u001b[39mfilenames_file_path_test,\n\u001b[0;32m     54\u001b[0m     class_info_file_path\u001b[38;5;241m=\u001b[39mclass_info_file_path_test,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mimage_size,\n\u001b[0;32m     58\u001b[0m )\n",
            "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mLoad dataset\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m filenames \u001b[38;5;241m=\u001b[39m load_filenames(filenames_file_path)\n\u001b[1;32m----> 6\u001b[0m class_ids \u001b[38;5;241m=\u001b[39m \u001b[43mload_class_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_info_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m bounding_boxes \u001b[38;5;241m=\u001b[39m load_bounding_boxes(cub_dataset_dir)\n\u001b[0;32m      8\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m load_embeddings(embeddings_file_path)\n",
            "Cell \u001b[1;32mIn[23], line 9\u001b[0m, in \u001b[0;36mload_class_ids\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_class_ids\u001b[39m(file_path):\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads class IDs from a pickle file.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     10\u001b[0m         class_ids \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m class_ids\n",
            "File \u001b[1;32mc:\\Users\\MSI\\anaconda3\\envs\\generalEnv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/coco/train\\\\class_info.pickle'"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # ----------------------------\n",
        "    # 1) Setup & Hyperparameters\n",
        "    # ----------------------------\n",
        "    data_dir = \"./data/coco/\"\n",
        "    train_dir = os.path.join(data_dir, \"train\")\n",
        "    test_dir = os.path.join(data_dir, \"val\")  # Using val as test\n",
        "\n",
        "    # Example: extract train2014 if train_dir is empty\n",
        "    if not os.listdir(train_dir):\n",
        "        with zipfile.ZipFile(os.path.join(data_dir, \"train2014\"), \"r\") as zip_ref:\n",
        "            zip_ref.extractall(train_dir)\n",
        "\n",
        "    # Create results directory if it doesn't exist\n",
        "    if not os.path.exists(\"results\"):\n",
        "        os.makedirs(\"results\")\n",
        "\n",
        "    image_size = (64, 64)\n",
        "    batch_size = 32\n",
        "    z_dim = 100\n",
        "    epochs = 10\n",
        "    embedding_dim = 1024\n",
        "    condition_dim = 128\n",
        "\n",
        "\n",
        "    # File paths for training\n",
        "    embeddings_file_path_train = os.path.join(train_dir, \"char-CNN-RNN-embeddings.pickle\")\n",
        "    filenames_file_path_train = os.path.join(train_dir, \"filenames.pickle\")\n",
        "    # class_info_file_path_train = os.path.join(train_dir, \"class_info.pickle\")\n",
        "\n",
        "    # Similarly for test data if needed\n",
        "    embeddings_file_path_test = os.path.join(test_dir, \"char-CNN-RNN-embeddings.pickle\")\n",
        "    filenames_file_path_test = os.path.join(test_dir, \"filenames.pickle\")\n",
        "\n",
        "    # Optimizers\n",
        "    dis_optimizer = optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
        "    gen_optimizer = optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "    # ----------------------------\n",
        "    # 2) Load Training Data\n",
        "    # ----------------------------\n",
        "    print(\"Loading training data...\")\n",
        "    X_train, y_train, embeddings_train = load_dataset(\n",
        "        filenames_file_path=filenames_file_path_train,\n",
        "        # class_info_file_path=class_info_file_path_train,\n",
        "        cub_dataset_dir=train_dir,\n",
        "        embeddings_file_path=embeddings_file_path_train,\n",
        "        image_size=image_size,\n",
        "    )\n",
        "\n",
        "    print(\"Loading test data...\")\n",
        "    X_test, y_test, embeddings_test = load_dataset(\n",
        "        filenames_file_path=filenames_file_path_test,\n",
        "        # class_info_file_path=class_info_file_path_test,\n",
        "        cub_dataset_dir=test_dir,\n",
        "        embeddings_file_path=embeddings_file_path_test,\n",
        "        image_size=image_size,\n",
        "    )\n",
        "\n",
        "    # ----------------------------\n",
        "    # 3) Build & Compile Models\n",
        "    # ----------------------------\n",
        "    print(\"Building models...\")\n",
        "    ca_model = build_ca_model(embedding_dim=embedding_dim, condition_dim=condition_dim)\n",
        "    embedding_compressor_model = build_embedding_compressor_model(\n",
        "        embedding_dim=embedding_dim, condition_dim=condition_dim\n",
        "    )\n",
        "    stage1_gen = build_stage1_generator(z_dim=z_dim, condition_dim=condition_dim)\n",
        "    stage1_dis = build_stage1_discriminator(condition_dim=condition_dim)\n",
        "\n",
        "    # Compile Discriminator\n",
        "    stage1_dis.compile(\n",
        "        loss=\"binary_crossentropy\", optimizer=dis_optimizer, metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # Adversarial model (for training Generator)\n",
        "    adversarial_model = build_adversarial_model(\n",
        "        gen_model=stage1_gen,\n",
        "        dis_model=stage1_dis,\n",
        "        ca_model=ca_model,\n",
        "        z_dim=z_dim,\n",
        "        condition_dim=condition_dim,\n",
        "    )\n",
        "    # We'll use the custom KL_loss for the second output\n",
        "    adversarial_model.compile(\n",
        "        loss=[\"binary_crossentropy\", KL_loss],\n",
        "        loss_weights=[1.0, 2.0],\n",
        "        optimizer=gen_optimizer,\n",
        "    )\n",
        "\n",
        "    # ----------------------------\n",
        "    # 4) Training Loop\n",
        "    # ----------------------------\n",
        "    real_labels = np.ones((batch_size, 1), dtype=np.float32) * 0.9\n",
        "    fake_labels = np.zeros((batch_size, 1), dtype=np.float32)\n",
        "\n",
        "    # Weâ€™ll assume embeddings_train.shape[0] == X_train.shape[0]\n",
        "    num_batches = X_train.shape[0] // batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"================== Epoch {epoch+1}/{epochs} ==================\")\n",
        "        np.random.shuffle(indices := np.arange(X_train.shape[0]))\n",
        "\n",
        "        for batch_i in range(num_batches):\n",
        "            # ---------------------------\n",
        "            # 4.1) Get real batch\n",
        "            # ---------------------------\n",
        "            batch_indices = indices[batch_i * batch_size : (batch_i + 1) * batch_size]\n",
        "            real_imgs = X_train[batch_indices]\n",
        "            real_embeddings = embeddings_train[batch_indices]\n",
        "\n",
        "            # ---------------------------\n",
        "            # 4.2) Sample random noise\n",
        "            # ---------------------------\n",
        "            z_noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "\n",
        "            # ---------------------------\n",
        "            # 4.3) Generate fake images\n",
        "            # ---------------------------\n",
        "            # Pass embeddings through CA to get c, then generate\n",
        "            mu, logvar = ca_model.predict_on_batch(real_embeddings)\n",
        "            epsilon = np.random.normal(0, 1, (batch_size, condition_dim))\n",
        "            c = mu + np.exp(logvar / 2) * epsilon  # reparameterize\n",
        "\n",
        "            gen_input = np.concatenate([z_noise, c], axis=1)\n",
        "            fake_imgs = stage1_gen.predict_on_batch(gen_input)\n",
        "\n",
        "            # ---------------------------\n",
        "            # 4.4) Train Discriminator\n",
        "            # ---------------------------\n",
        "            # 4.4.1) Train on real\n",
        "            d_loss_real = stage1_dis.train_on_batch([real_imgs, c], real_labels)\n",
        "\n",
        "            # 4.4.2) Train on fake\n",
        "            d_loss_fake = stage1_dis.train_on_batch([fake_imgs, c], fake_labels)\n",
        "\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ---------------------------\n",
        "            # 4.5) Train Generator\n",
        "            # ---------------------------\n",
        "            # We want the generator to produce images that the discriminator\n",
        "            # classifies as real (label=1.0), plus we want to minimize KL divergence\n",
        "            # The adversarial_model takes [z, embedding] -> [D_out, mu_logvar]\n",
        "            # So we must feed real_embeddings again (for CA) plus z_noise\n",
        "            valid_y = np.ones(\n",
        "                (batch_size, 1), dtype=np.float32\n",
        "            )  # generator wants them real\n",
        "            # For the KL loss, we pass a dummy array (shape=(batch_size, condition_dim*2))\n",
        "            # or we rely on the model to parse it. Let's just pass zeros:\n",
        "            dummy_kl = np.zeros((batch_size, condition_dim * 2), dtype=np.float32)\n",
        "\n",
        "            g_loss = adversarial_model.train_on_batch(\n",
        "                [z_noise, real_embeddings], [valid_y, dummy_kl]\n",
        "            )\n",
        "\n",
        "            # Print every few batches\n",
        "            if batch_i % 50 == 0:\n",
        "                print(\n",
        "                    f\"Batch {batch_i}/{num_batches} | D loss: {d_loss[0]:.4f} | G loss: {g_loss[0]:.4f} (KL: {g_loss[1]:.4f})\"\n",
        "                )\n",
        "\n",
        "        # ---------------------------\n",
        "        # 4.6) Save Weights Periodically\n",
        "        # ---------------------------\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            stage1_gen.save_weights(f\"stage1_gen_epoch_{epoch+1}.keras\")\n",
        "            stage1_dis.save_weights(f\"stage1_dis_epoch_{epoch+1}.keras\")\n",
        "\n",
        "    # ----------------------------\n",
        "    # 5) Final Save\n",
        "    # ----------------------------\n",
        "    stage1_gen.save_weights(\"stage1_gen_final.keras\")\n",
        "    stage1_dis.save_weights(\"stage1_dis_final.keras\")\n",
        "    print(\"Training complete!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "psC9UHjzliA1",
        "XZybHodapH3H",
        "ODvYdkGtpGKJ",
        "eNBHRmpqpZgo"
      ],
      "include_colab_link": true,
      "name": "stackgan_stage_I_imp.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "generalEnv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
