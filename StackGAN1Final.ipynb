{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames_file_path, embeddings_file_path, image_size, dataset_dir, class_info_file_path=None):\n",
    "    \"\"\"\n",
    "    Load COCO dataset\n",
    "    \"\"\"\n",
    "    # Load filenames\n",
    "    with open(filenames_file_path, 'rb') as f:\n",
    "        filenames = pickle.load(f)\n",
    "    \n",
    "    # Load class IDs if available\n",
    "    if class_info_file_path is not None and os.path.exists(class_info_file_path):\n",
    "        with open(class_info_file_path, 'rb') as f:\n",
    "            class_ids = pickle.load(f)\n",
    "    else:\n",
    "        # If no class info provided, assign a default class ID of 0\n",
    "        class_ids = [0] * len(filenames)\n",
    "    \n",
    "    # Load embeddings\n",
    "    with open(embeddings_file_path, 'rb') as f:\n",
    "        all_embeddings = pickle.load(f)\n",
    "        # Convert to NumPy array if it's a list\n",
    "        if isinstance(all_embeddings, list):\n",
    "            all_embeddings = np.array(all_embeddings)\n",
    "    \n",
    "    # Verify that the number of embeddings matches the number of filenames\n",
    "    if len(all_embeddings) != len(filenames):\n",
    "        raise ValueError(f\"Number of embeddings ({len(all_embeddings)}) does not match number of filenames ({len(filenames)})\")\n",
    "    \n",
    "    print(f\"Number of images with embeddings: {len(all_embeddings)}\")\n",
    "    print(f\"Shape of embeddings for first image: {all_embeddings[0].shape}\")\n",
    "    \n",
    "    X, y, embeddings = [], [], []\n",
    "    \n",
    "    # Determine if we're working with train or validation data\n",
    "    # Use the coco2014 directory instead of coco\n",
    "    if \"train\" in dataset_dir:\n",
    "        images_dir = \"./data/coco2014/train2014\"\n",
    "    else:\n",
    "        images_dir = \"./data/coco2014/val2014\"\n",
    "    \n",
    "    for index, filename in enumerate(filenames):\n",
    "        try:\n",
    "            # Get just the basename (the filename without the path)\n",
    "            base_filename = os.path.basename(filename)\n",
    "            \n",
    "            # Construct the correct image path\n",
    "            img_name = os.path.join(images_dir, base_filename)\n",
    "            \n",
    "            # Load and resize the image\n",
    "            img = Image.open(img_name).convert('RGB')\n",
    "            img = img.resize(image_size, Image.LANCZOS if hasattr(Image, 'LANCZOS') else Image.ANTIALIAS)\n",
    "            img = np.array(img) / 127.5 - 1.0  # Normalize to [-1, 1]\n",
    "            \n",
    "            # Get embedding for this image\n",
    "            all_embeddings1 = all_embeddings[index]  # Shape: (10, 1, 1024)\n",
    "            \n",
    "            # Randomly select one embedding from the available ones\n",
    "            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n",
    "            embedding = all_embeddings1[embedding_ix].squeeze()  # From (1, 1024) to (1024,)\n",
    "            \n",
    "            X.append(img)\n",
    "            y.append(class_ids[index])\n",
    "            embeddings.append(embedding)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {base_filename}: {e}\")\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    embeddings = np.array(embeddings)\n",
    "    \n",
    "    return X, y, embeddings\n",
    "\n",
    "def load_filenames(file_path):\n",
    "    \"\"\"Loads filenames from a pickle file.\"\"\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        filenames = pickle.load(f)\n",
    "    return filenames\n",
    "\n",
    "def load_class_ids(file_path):\n",
    "    \"\"\"Loads class IDs from a pickle file.\"\"\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        class_ids = pickle.load(f)\n",
    "    return class_ids\n",
    "\n",
    "def load_bounding_boxes(cub_dataset_dir):\n",
    "    \"\"\"\n",
    "    Placeholder: In real code, you'd load bounding boxes from .txt or .pickle.\n",
    "    Returns a dict of {filename: (x, y, width, height)} or similar.\n",
    "    \"\"\"\n",
    "    # For simplicity, return an empty dict or random boxes\n",
    "    return {}\n",
    "\n",
    "def load_embeddings(embeddings_file_path):\n",
    "    \"\"\"Loads embeddings from a pickle file.\"\"\"\n",
    "    with open(embeddings_file_path, \"rb\") as f:\n",
    "        all_embeddings = pickle.load(f)\n",
    "    return all_embeddings\n",
    "\n",
    "def get_img(img_path, bounding_box, image_size):\n",
    "    \"\"\"\n",
    "    Loads and returns a resized image. \n",
    "    bounding_box is ignored here, but you could crop the image accordingly if needed.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = img.resize(image_size, Image.ANTIALIAS)\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Conditioning Augmentation (CA) Model\n",
    "\n",
    "#    Takes an embedding and learns mu/logvar, then reparameterizes to produce c\n",
    "\n",
    "def build_ca_model(embedding_dim=1024, condition_dim=128):\n",
    "    \"\"\"\n",
    "    CA model that takes text embedding of size embedding_dim and\n",
    "    outputs a (condition_dim)-dim vector c after reparameterization.\n",
    "    \"\"\"\n",
    "    embedding_input = layers.Input(shape=(embedding_dim,))\n",
    "    x = layers.Dense(256, activation=\"relu\")(embedding_input)\n",
    "    mu = layers.Dense(condition_dim)(x)\n",
    "    logvar = layers.Dense(condition_dim)(x)\n",
    "\n",
    "    # We'll output mu and logvar; the reparameterization trick can be done outside\n",
    "    model = keras.Model(inputs=embedding_input, outputs=[mu, logvar])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 2) KL Divergence Loss for the CA Model\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def KL_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    The second output of the adversarial model is (mu, logvar),\n",
    "    but we typically compute KL inside the CA pipeline. \n",
    "    Here is a placeholder that expects y_pred = [mu, logvar] concatenated \n",
    "    or another custom approach. For simplicity, let's do a naive version.\n",
    "    \"\"\"\n",
    "    # Suppose we packed mu and logvar along the last dimension\n",
    "    # i.e. y_pred.shape == (batch_size, condition_dim*2)\n",
    "    half = y_pred.shape[-1] // 2\n",
    "    mu = y_pred[:, :half]\n",
    "    logvar = y_pred[:, half:]\n",
    "    # KL\n",
    "    kld = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mu) - tf.exp(logvar), axis=1)\n",
    "    return tf.reduce_mean(kld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 3) Embedding Compressor (optional)\n",
    "#    Sometimes used to reduce embedding dim (e.g., 1024 -> 128)\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def build_embedding_compressor_model(embedding_dim=1024, condition_dim=128):\n",
    "    \"\"\"\n",
    "    Simple FC to reduce large embedding_dim -> condition_dim\n",
    "    \"\"\"\n",
    "    embedding_input = layers.Input(shape=(embedding_dim,))\n",
    "    x = layers.Dense(condition_dim, activation=\"relu\")(embedding_input)\n",
    "    model = keras.Model(inputs=embedding_input, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 4) Stage 1 Generator\n",
    "#    Takes random noise z + condition c, outputs a 64x64 image\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def build_stage1_generator(z_dim=100, condition_dim=128):\n",
    "    input_layer = layers.Input(shape=(z_dim + condition_dim,))\n",
    "    \n",
    "    x = layers.Dense(4*4*256, use_bias=False)(input_layer)\n",
    "    x = layers.Reshape((4, 4, 256))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding=\"same\", use_bias=False)(x)  # (8, 8, 128)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, (4,4), strides=(2,2), padding=\"same\", use_bias=False)(x)   # (16, 16, 64)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(32, (4,4), strides=(2,2), padding=\"same\", use_bias=False)(x)   # (32, 32, 32)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(3, (4,4), strides=(2,2), padding=\"same\", use_bias=False)(x)    # (64, 64, 3)\n",
    "    x = layers.Activation(\"tanh\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 5) Stage 1 Discriminator\n",
    "#    Takes 64x64 image + condition embedding, outputs real/fake\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def build_stage1_discriminator(condition_dim):\n",
    "    \"\"\"\n",
    "    Build Stage 1 Discriminator - PatchGAN with global averaging\n",
    "    \"\"\"\n",
    "    # Image input\n",
    "    input_img = layers.Input(shape=(64, 64, 3))\n",
    "    \n",
    "    # First conv block\n",
    "    x_img = layers.Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\")(input_img)  # (32, 32, 64)\n",
    "    x_img = layers.LeakyReLU(0.2)(x_img)\n",
    "    \n",
    "    # Second conv block\n",
    "    x_img = layers.Conv2D(128, (4, 4), strides=(2, 2), padding=\"same\")(x_img)  # (16, 16, 128)\n",
    "    x_img = layers.BatchNormalization()(x_img)\n",
    "    x_img = layers.LeakyReLU(0.2)(x_img)\n",
    "    \n",
    "    # Third conv block\n",
    "    x_img = layers.Conv2D(256, (4, 4), strides=(2, 2), padding=\"same\")(x_img)  # (8, 8, 256)\n",
    "    x_img = layers.BatchNormalization()(x_img)\n",
    "    x_img = layers.LeakyReLU(0.2)(x_img)\n",
    "    \n",
    "    # Condition input\n",
    "    input_cond = layers.Input(shape=(condition_dim,))\n",
    "    \n",
    "    # Process condition and reshape it to match the spatial dimensions of x_img (8x8)\n",
    "    cond = layers.Dense(condition_dim)(input_cond)\n",
    "    cond = layers.Reshape((1, 1, condition_dim))(cond)\n",
    "    cond = layers.UpSampling2D(size=(8, 8))(cond)  # (8, 8, condition_dim)\n",
    "    \n",
    "    # Concatenate condition map with image\n",
    "    x = layers.Concatenate(axis=-1)([x_img, cond])  # (8, 8, 256 + condition_dim)\n",
    "    \n",
    "    x = layers.Conv2D(256, (3,3), strides=(1,1), padding=\"same\")(x)  # (8, 8, 256)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    x = layers.Conv2D(1, (4,4), strides=(1,1), padding=\"same\")(x)  # (8, 8, 1)\n",
    "    x = layers.Activation(\"sigmoid\")(x)  # (8, 8, 1)\n",
    "    \n",
    "    # Average the patch predictions to get a single scalar\n",
    "    # x = layers.GlobalAveragePooling2D()(x)  # (1,)\n",
    "    \n",
    "    # Create model\n",
    "    model = keras.Model([input_img, input_cond], x, name=\"stage1_discriminator\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 6) Adversarial Model\n",
    "#    Wires up Generator + Discriminator for generator training\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def build_adversarial_model(gen_model, dis_model, ca_model, z_dim, condition_dim):\n",
    "    \"\"\"\n",
    "    Build the adversarial model for generator training\n",
    "    \"\"\"\n",
    "    # Freeze discriminator weights during generator training\n",
    "    dis_model.trainable = False\n",
    "    \n",
    "    # Inputs\n",
    "    z_input = layers.Input(shape=(z_dim,))\n",
    "    embedding_input = layers.Input(shape=(1024,))\n",
    "    \n",
    "    # CA model -> mu, logvar\n",
    "    mu, logvar = ca_model(embedding_input)\n",
    "    \n",
    "    # Sample c ~ N(mu, sigma)\n",
    "    # Define the output shape for the Lambda layer\n",
    "    def random_normal_output_shape(input_shape):\n",
    "        return input_shape  # epsilon should have the same shape as mu\n",
    "    \n",
    "    epsilon = layers.Lambda(\n",
    "        lambda x: K.random_normal(shape=K.shape(x)),\n",
    "        output_shape=random_normal_output_shape\n",
    "    )(mu)\n",
    "    \n",
    "    # Compute c using the reparameterization trick\n",
    "    c = layers.Lambda(\n",
    "        lambda inputs: inputs[0] + K.exp(inputs[1] / 2) * inputs[2],\n",
    "        output_shape=(condition_dim,)  # c has shape (batch_size, condition_dim)\n",
    "    )([mu, logvar, epsilon])\n",
    "    \n",
    "    # Combine z and c\n",
    "    z_c = layers.Concatenate()([z_input, c])\n",
    "    \n",
    "    # Generate image\n",
    "    fake_img = gen_model(z_c)\n",
    "    \n",
    "    # Get discriminator output\n",
    "    dis_output = dis_model([fake_img, c])\n",
    "    \n",
    "    # The model outputs both the discriminator output and the CA output (mu, logvar)\n",
    "    model = keras.Model(\n",
    "        [z_input, embedding_input], [dis_output, layers.Concatenate()([mu, logvar])]\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Number of images with embeddings: 999\n",
      "Shape of embeddings for first image: (10, 1, 1024)\n",
      "Loading test data...\n",
      "Number of images with embeddings: 200\n",
      "Shape of embeddings for first image: (10, 1, 1024)\n",
      "Building models...\n",
      "================== Epoch 1/20 ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\.conda\\envs\\generalEnv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/31 | D loss: 0.6991 | G loss: 0.8577 (KL: 0.6475)\n",
      "================== Epoch 2/20 ==================\n",
      "Batch 0/31 | D loss: 0.7277 | G loss: 0.6813 (KL: 0.5916)\n",
      "================== Epoch 3/20 ==================\n",
      "Batch 0/31 | D loss: 0.7321 | G loss: 0.6317 (KL: 0.5723)\n",
      "================== Epoch 4/20 ==================\n",
      "Batch 0/31 | D loss: 0.7383 | G loss: 0.6059 (KL: 0.5612)\n",
      "================== Epoch 5/20 ==================\n",
      "Batch 0/31 | D loss: 0.7449 | G loss: 0.5893 (KL: 0.5534)\n",
      "================== Epoch 6/20 ==================\n",
      "Batch 0/31 | D loss: 0.7515 | G loss: 0.5783 (KL: 0.5480)\n",
      "================== Epoch 7/20 ==================\n",
      "Batch 0/31 | D loss: 0.7580 | G loss: 0.5697 (KL: 0.5435)\n",
      "================== Epoch 8/20 ==================\n",
      "Batch 0/31 | D loss: 0.7637 | G loss: 0.5622 (KL: 0.5390)\n",
      "================== Epoch 9/20 ==================\n",
      "Batch 0/31 | D loss: 0.7687 | G loss: 0.5556 (KL: 0.5347)\n",
      "================== Epoch 10/20 ==================\n",
      "Batch 0/31 | D loss: 0.7731 | G loss: 0.5514 (KL: 0.5323)\n",
      "================== Epoch 11/20 ==================\n",
      "Batch 0/31 | D loss: 0.7772 | G loss: 0.5474 (KL: 0.5298)\n",
      "================== Epoch 12/20 ==================\n",
      "Batch 0/31 | D loss: 0.7809 | G loss: 0.5443 (KL: 0.5279)\n",
      "================== Epoch 13/20 ==================\n",
      "Batch 0/31 | D loss: 0.7845 | G loss: 0.5414 (KL: 0.5261)\n",
      "================== Epoch 14/20 ==================\n",
      "Batch 0/31 | D loss: 0.7875 | G loss: 0.5392 (KL: 0.5247)\n",
      "================== Epoch 15/20 ==================\n",
      "Batch 0/31 | D loss: 0.7904 | G loss: 0.5370 (KL: 0.5232)\n",
      "================== Epoch 16/20 ==================\n",
      "Batch 0/31 | D loss: 0.7927 | G loss: 0.5347 (KL: 0.5216)\n",
      "================== Epoch 17/20 ==================\n",
      "Batch 0/31 | D loss: 0.7948 | G loss: 0.5326 (KL: 0.5201)\n",
      "================== Epoch 18/20 ==================\n",
      "Batch 0/31 | D loss: 0.7970 | G loss: 0.5312 (KL: 0.5192)\n",
      "================== Epoch 19/20 ==================\n",
      "Batch 0/31 | D loss: 0.7989 | G loss: 0.5294 (KL: 0.5178)\n",
      "================== Epoch 20/20 ==================\n",
      "Batch 0/31 | D loss: 0.8007 | G loss: 0.5280 (KL: 0.5169)\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 1) Setup & Hyperparameters\n",
    "\n",
    "    data_dir = \"./data/coco/\"\n",
    "    train_dir = os.path.join(data_dir, \"train\")\n",
    "    test_dir = os.path.join(data_dir, \"val\")  # Using val as test\n",
    "\n",
    "    # Example: extract train2014 if train_dir is empty\n",
    "    if not os.listdir(train_dir):\n",
    "        with zipfile.ZipFile(os.path.join(data_dir, \"train2014\"), \"r\") as zip_ref:\n",
    "            zip_ref.extractall(train_dir)\n",
    "\n",
    "    # Create results directory if it doesn't exist\n",
    "    if not os.path.exists(\"results\"):\n",
    "        os.makedirs(\"results\")\n",
    "\n",
    "    image_size = (64, 64)\n",
    "    batch_size = 32\n",
    "    z_dim = 100\n",
    "    epochs = 20\n",
    "    embedding_dim = 1024\n",
    "    condition_dim = 128\n",
    "\n",
    "\n",
    "    # File paths for training\n",
    "    embeddings_file_path_train = os.path.join(train_dir, \"char-CNN-RNN-embeddings.pickle\")\n",
    "    filenames_file_path_train = os.path.join(train_dir, \"filenames.pickle\")\n",
    "    # class_info_file_path_train = os.path.join(train_dir, \"class_info.pickle\")\n",
    "\n",
    "    # Similarly for test data if needed\n",
    "    embeddings_file_path_test = os.path.join(test_dir, \"char-CNN-RNN-embeddings.pickle\")\n",
    "    filenames_file_path_test = os.path.join(test_dir, \"filenames.pickle\")\n",
    "\n",
    "    # Optimizers\n",
    "    dis_optimizer = optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "    gen_optimizer = optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "\n",
    "    # 2) Load Training Data\n",
    "\n",
    "    print(\"Loading training data...\")\n",
    "    X_train, y_train, embeddings_train = load_dataset(\n",
    "        filenames_file_path=filenames_file_path_train,\n",
    "        embeddings_file_path=embeddings_file_path_train,\n",
    "        image_size=image_size,\n",
    "        dataset_dir=train_dir,\n",
    "        # class_info_file_path=class_info_file_path_train,\n",
    "    )\n",
    "\n",
    "    print(\"Loading test data...\")\n",
    "    X_test, y_test, embeddings_test = load_dataset(\n",
    "        filenames_file_path=filenames_file_path_test,\n",
    "        embeddings_file_path=embeddings_file_path_test,\n",
    "        image_size=image_size,\n",
    "        dataset_dir=test_dir,\n",
    "        # class_info_file_path=class_info_file_path_test,\n",
    "    )\n",
    "\n",
    "\n",
    "    # 3) Build & Compile Models\n",
    "\n",
    "    print(\"Building models...\")\n",
    "\n",
    "\n",
    "    ca_model = build_ca_model(embedding_dim=embedding_dim, condition_dim=condition_dim)\n",
    "\n",
    "    embedding_compressor_model = build_embedding_compressor_model(\n",
    "        embedding_dim=embedding_dim, condition_dim=condition_dim\n",
    "    )\n",
    "\n",
    "\n",
    "    stage1_gen = build_stage1_generator(z_dim=z_dim, condition_dim=condition_dim)\n",
    "    \n",
    "    stage1_dis = build_stage1_discriminator(condition_dim=condition_dim)\n",
    "\n",
    "    # Compile Discriminator\n",
    "    stage1_dis.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer=dis_optimizer, metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Adversarial model (for training Generator)\n",
    "    adversarial_model = build_adversarial_model(\n",
    "        gen_model=stage1_gen,\n",
    "        dis_model=stage1_dis,\n",
    "        ca_model=ca_model,\n",
    "        z_dim=z_dim,\n",
    "        condition_dim=condition_dim,\n",
    "    )\n",
    "    # We'll use the custom KL_loss for the second output\n",
    "    adversarial_model.compile(\n",
    "        loss=[\"binary_crossentropy\", KL_loss],\n",
    "        loss_weights=[1.0, 2.0],\n",
    "        optimizer=gen_optimizer,\n",
    "    )\n",
    "\n",
    "\n",
    "    # 4) Training Loop\n",
    "\n",
    "   # Update label shapes for PatchGAN\n",
    "real_labels = np.ones((batch_size, 8, 8, 1), dtype=np.float32) * 0.9  # Shape: (32, 8, 8, 1)\n",
    "fake_labels = np.zeros((batch_size, 8, 8, 1), dtype=np.float32)        # Shape: (32, 8, 8, 1)\n",
    "\n",
    "# We’ll assume embeddings_train.shape[0] == X_train.shape[0]\n",
    "num_batches = X_train.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"================== Epoch {epoch+1}/{epochs} ==================\")\n",
    "    np.random.shuffle(indices := np.arange(X_train.shape[0]))\n",
    "\n",
    "    for batch_i in range(num_batches):\n",
    "        # ---------------------------\n",
    "        # 4.1) Get real batch\n",
    "        # ---------------------------\n",
    "        batch_indices = indices[batch_i * batch_size : (batch_i + 1) * batch_size]\n",
    "        real_imgs = X_train[batch_indices]\n",
    "        real_embeddings = embeddings_train[batch_indices]\n",
    "\n",
    "        # ---------------------------\n",
    "        # 4.2) Sample random noise\n",
    "        # ---------------------------\n",
    "        z_noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "\n",
    "        # ---------------------------\n",
    "        # 4.3) Generate fake images\n",
    "        # ---------------------------\n",
    "        mu, logvar = ca_model.predict_on_batch(real_embeddings)\n",
    "        epsilon = np.random.normal(0, 1, (batch_size, condition_dim))\n",
    "        c = mu + np.exp(logvar / 2) * epsilon  # reparameterize\n",
    "\n",
    "        gen_input = np.concatenate([z_noise, c], axis=1)\n",
    "        fake_imgs = stage1_gen.predict_on_batch(gen_input)\n",
    "\n",
    "        # ---------------------------\n",
    "        # 4.4) Train Discriminator\n",
    "        # ---------------------------\n",
    "        # 4.4.1) Train on real\n",
    "        d_loss_real = stage1_dis.train_on_batch([real_imgs, c], real_labels)\n",
    "\n",
    "        # 4.4.2) Train on fake\n",
    "        d_loss_fake = stage1_dis.train_on_batch([fake_imgs, c], fake_labels)\n",
    "\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------------\n",
    "        # 4.5) Train Generator\n",
    "        # ---------------------------\n",
    "        valid_y = np.ones((batch_size, 8, 8, 1), dtype=np.float32)  # Update for generator training\n",
    "        dummy_kl = np.zeros((batch_size, condition_dim * 2), dtype=np.float32)\n",
    "\n",
    "        g_loss = adversarial_model.train_on_batch(\n",
    "            [z_noise, real_embeddings], [valid_y, dummy_kl]\n",
    "        )\n",
    "\n",
    "        # Print every few batches\n",
    "        if batch_i % 50 == 0:\n",
    "            print(\n",
    "                f\"Batch {batch_i}/{num_batches} | D loss: {d_loss[0]:.4f} | G loss: {g_loss[0]:.4f} (KL: {g_loss[1]:.4f})\"\n",
    "            )\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4.6) Save Weights Periodically\n",
    "    # ---------------------------\n",
    "    model_save_dir = \"model_weights/stage1\"\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        stage1_gen.save_weights(os.path.join(model_save_dir, f\"stage1_gen_epoch_{epoch+1}.weights.h5\"))\n",
    "        stage1_dis.save_weights(os.path.join(model_save_dir, f\"stage1_dis_epoch_{epoch+1}.weights.h5\"))\n",
    "\n",
    "# 5) Final Save\n",
    "stage1_gen.save_weights(os.path.join(model_save_dir, \"stage1_gen_final.weights.h5\"))\n",
    "stage1_dis.save_weights(os.path.join(model_save_dir, \"stage1_dis_final.weights.h5\"))\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
